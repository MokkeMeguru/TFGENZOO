{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFGENZOO_Tutorial (1)",
      "provenance": [],
      "collapsed_sections": [
        "xCocI6HkSU1e"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtBSaeMy691o",
        "colab_type": "text"
      },
      "source": [
        "# TFGENZOO_Tutorial (1) What is the invertible layer\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/MokkeMeguru/TFGENZOO/blob/master/tutorials/01_What_is_the_invertible_layer.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaFTbnor7L8v",
        "colab_type": "text"
      },
      "source": [
        "Invertible layer is the component of the Flow-based Model.\n",
        "\n",
        "Flow-based Model is one of the generative neural networks like GANs and VAEs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prBLMb4d8a57",
        "colab_type": "text"
      },
      "source": [
        "![abstflow.png](https://raw.githubusercontent.com/MokkeMeguru/TFGENZOO/master/tutorials/img/abstflow.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnkxUoGg8fux",
        "colab_type": "text"
      },
      "source": [
        "\"**Invertible**\", is the importest word in Flow-based Model.\n",
        "\n",
        "We **should** use  bi-directional function as each layer.\n",
        "\n",
        "These layers constructs the Flow-based Model like OpenAI's Glow, Google's RealNVP, NeuralODE, and i-RevNet / i-ResNet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yWRcok09OZj",
        "colab_type": "text"
      },
      "source": [
        "# What is the TFGENZOO\n",
        "TFGENZOO is the library  to help constructing generative neural networks. \n",
        "\n",
        "Now (v1.2.x) ,  we supported to construct basic Flow-based Model like Glow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbNxnFboHDmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "d0fd3561-039d-40b3-f6a1-2824ec5aefa8"
      },
      "source": [
        "# Install TFGENZOO\n",
        "!pip install TFGENZOO==1.2.4.post6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKWgQLokHgqi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c91b7ed9-6962-4410-e2a1-714966e472bd"
      },
      "source": [
        "import tensorflow as tf\n",
        "import TFGENZOO\n",
        "print(f'Tensorflow {tf.__version__} / TFGENZO {TFGENZOO.__version__}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow 2.2.0 / TFGENZO 1.2.4.post6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfIa_shWLUKH",
        "colab_type": "text"
      },
      "source": [
        "# Three components of Flow-based Model\n",
        "The main components of Flow-based Model is \n",
        "\n",
        "1. Normalizing\n",
        "2. Permuting\n",
        "3. Coupling\n",
        "\n",
        "Normalizing is the layer to normalize **input tensor**.\n",
        "\n",
        "Permuting is the layer that shuffle element of input tensor.\n",
        "\n",
        "Coupling is the layer is convert the input tensor into the tensor following the distribution e.g. gaussian.\n",
        "\n",
        "We implemented some basic Layer with detailed document. \n",
        "If you want to know the formula or implementation detail, please visit our Documentation from the repo. https://github.com/MokkeMeguru/TFGENZOO .\n",
        "\n",
        "And also, you can confirm the  document from  your coding environment such as VSCode or Emacs or Vim with Python Language Server Protocol."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCocI6HkSU1e",
        "colab_type": "text"
      },
      "source": [
        "## Normalization : Actnorm\n",
        "Actnorm is the layer  proposed in Glow (OpenAI) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaNSMtBoNQKT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fff8ac43-4859-4e59-f091-14d3ebdaf8ff"
      },
      "source": [
        "from TFGENZOO.flows import Actnorm\n",
        "\n",
        "actnorm = Actnorm()\n",
        "\n",
        "# input data is the 3-D data like the rgb image.\n",
        "x = tf.random.normal([16, 32, 32, 3])\n",
        "\n",
        "# here is the forward function\n",
        "z, log_det_jacobian = actnorm(x)\n",
        "\n",
        "# here is the inverse function\n",
        "\n",
        "rev_x, inverse_log_det_jacobian = actnorm(z, inverse=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initialization at actnorm_20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu2kg7v6T3BZ",
        "colab_type": "text"
      },
      "source": [
        "You can see the message \"initialization at actrnom\".\n",
        "\n",
        "It is the important log about Actnorm.\n",
        "Actrnom requires **data-dependent initialization** which initialize the first batch of dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-JeDHXJUJ1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6fbdf3c1-1641-4654-b671-160cc31096b7"
      },
      "source": [
        "print(f'reconstruction loss is {tf.reduce_mean((rev_x - x)**2)}, and also, reconstruction effect is  {tf.reduce_mean(log_det_jacobian + inverse_log_det_jacobian)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reconstruction loss is 2.8776044911580636e-15, and also, reconstruction effect is  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HthJQxnwVA9j",
        "colab_type": "text"
      },
      "source": [
        "## Permutation: Inv1x1Conv\n",
        "Invertible 1x1Conv is  proposed in Glow (OpenAI)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E0QArSHVJYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7cf09fe6-d309-407c-fe55-ac20ad4bf72d"
      },
      "source": [
        "from TFGENZOO.flows import Inv1x1Conv\n",
        "\n",
        "inv1x1Conv = Inv1x1Conv()\n",
        "\n",
        "# input data is the 3-D data like the rgb image.\n",
        "x = tf.random.normal([16, 32, 32, 3])\n",
        "\n",
        "# here is the forward function\n",
        "z, log_det_jacobian = inv1x1Conv(x)\n",
        "\n",
        "# here is the inverse function\n",
        "\n",
        "rev_x, inverse_log_det_jacobian = inv1x1Conv(z, inverse=True)\n",
        "\n",
        "print(f'reconstruction loss is {tf.reduce_mean((rev_x - x)**2)}, and also, reconstruction effect is  {tf.reduce_mean(log_det_jacobian + inverse_log_det_jacobian)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reconstruction loss is 9.438383946202156e-15, and also, reconstruction effect is  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9aF1C45FCYN",
        "colab_type": "text"
      },
      "source": [
        "## Coupling: AffineCoupling\n",
        "AffineCoupling is proposed in RealNVP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYJPVrJM5wvE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3988ae29-f02c-482f-b5a2-65e77dd4a503"
      },
      "source": [
        "from TFGENZOO.flows import AffineCoupling\n",
        "import tensorflow.keras.layers as layers\n",
        "\n",
        "channel = 6\n",
        "assert channel % 2 == 0\n",
        "\n",
        "scale_shift_net = tf.keras.Sequential([\n",
        "                                       layers.Conv2D(32, 3, padding=\"same\"),\n",
        "                                       layers.Conv2D(64, 3, padding=\"same\"),\n",
        "                                       layers.Conv2D(64, 3, padding=\"same\"),\n",
        "                                       layers.Conv2D(channel, 3, padding=\"same\")])\n",
        "\n",
        "affineCoupling = AffineCoupling(scale_shift_net=scale_shift_net)\n",
        "\n",
        "# input data is the 3-D data like the rgb image.\n",
        "x = tf.random.normal([16, 16, 16, channel])\n",
        "\n",
        "# here is the forward function\n",
        "z, log_det_jacobian = affineCoupling(x)\n",
        "\n",
        "# here is the inverse function\n",
        "\n",
        "rev_x, inverse_log_det_jacobian = affineCoupling(z, inverse=True)\n",
        "\n",
        "print(f'reconstruction loss is {tf.reduce_mean((rev_x - x)**2)}, and also, reconstruction effect is  {tf.reduce_mean(log_det_jacobian + inverse_log_det_jacobian)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reconstruction loss is 8.330419217293498e-16, and also, reconstruction effect is  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSNmaM7-FQBE",
        "colab_type": "text"
      },
      "source": [
        "# A Step of Flow: Norm. + Perm. + Coupling\n",
        "We generally use the set of flow layers, Norm.+ Perm. + Coupling as **A Step of Flow**\n",
        "\n",
        "We can construct the set as **FlowModule**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goLjKcR6HrT6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d107ad7b-9391-4dda-b63c-2931aaceedd5"
      },
      "source": [
        "from TFGENZOO.flows import FlowModule\n",
        "from TFGENZOO.layers.resnet import ShallowResNet\n",
        "\n",
        "channel = 6\n",
        "assert channel % 2 == 0\n",
        "\n",
        "fm = []\n",
        "fm.append(Actnorm())\n",
        "fm.append(Inv1x1Conv())\n",
        "fm.append(AffineCoupling(scale_shift_net_template=lambda x: ShallowResNet(x)))\n",
        "\n",
        "stepOfFlow = FlowModule(fm)\n",
        "\n",
        "\n",
        "x = tf.random.normal([16, 16, 16, channel])\n",
        "\n",
        "# here is the forward function\n",
        "z, ldj = stepOfFlow(x)\n",
        "\n",
        "# here is the inverse function\n",
        "rev_x, ildj = stepOfFlow(z, inverse=True)\n",
        "\n",
        "print(f'reconstruction loss is {tf.reduce_mean((rev_x - x)**2)}, and also, reconstruction effect is  {tf.reduce_mean(log_det_jacobian + inverse_log_det_jacobian)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initialization at actnorm_32\n",
            "initialization at actnorm_activation_46\n",
            "initialization at actnorm_activation_47\n",
            "reconstruction loss is 1.3926969081830883e-14, and also, reconstruction effect is  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK9aOrDTFGa3",
        "colab_type": "text"
      },
      "source": [
        "This procedure is the same as the below code. (To simplify, the below example removes the calculation about log_det_jacobian)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNOkfuFtDcm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a886d462-be3a-445d-c77c-80b918ff1864"
      },
      "source": [
        "actnorm = Actnorm()\n",
        "inv1x1Conv = Inv1x1Conv()\n",
        "affineCoupling = AffineCoupling(scale_shift_net_template=lambda x: ShallowResNet(x))\n",
        "\n",
        "tx = x\n",
        "tx, _ = actnorm(tx)\n",
        "tx, _ = inv1x1Conv(tx)\n",
        "tx, _ = affineCoupling(tx)\n",
        "\n",
        "tz = tx\n",
        "tz,_ = affineCoupling(tz, inverse=True)\n",
        "tz,_ = inv1x1Conv(tz, inverse=True)\n",
        "tz,_  = actnorm(tz, inverse=True)\n",
        "\n",
        "rev_x = tz\n",
        "\n",
        "print(f'reconstruction loss is {tf.reduce_mean((rev_x - x)**2)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initialization at actnorm_31\n",
            "initialization at actnorm_activation_44\n",
            "initialization at actnorm_activation_45\n",
            "reconstruction loss is 1.2398427824775876e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PHjK0F5Fqnm",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "- Flow-based Model is the invertible neural network. Besides, this model is constructed by some invertible layers.\n",
        "- The main layers of invertible layers are **Normalization**,  **Permutation** and **Coupling**\n",
        "- The set of the three layer is often called **A step of Flow**."
      ]
    }
  ]
}
